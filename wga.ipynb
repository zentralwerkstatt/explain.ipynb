{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "\n",
    "https://www.wga.hu/ provides approximately 45,000 photos or scans of (mostly Western) works of art. \n",
    "\n",
    "## Disclaimer\n",
    "\n",
    "The dataset is available via a web interface. The website itself makes no claim as to their general policy on the automated download of these images for machine learning purposes, so indvidual permission should be obtained before running this script. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Please refer to the [README.md](README.md) for proper installation of the dependencies listed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use gevent to significntly speed up the download by running it in parallel\n",
    "import gevent\n",
    "from gevent import monkey\n",
    "monkey.patch_all()\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "from shutil import copyfile\n",
    "import random\n",
    "import PIL\n",
    "from IPython.display import clear_output, Image, display\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n",
    "\n",
    "- `source`: This should not be changed unless the file has been moved on the server.are `InceptionV3` and `VGG16`.\n",
    "- `dir`: Name of the directory to download to.\n",
    "- `cc`: Number of images to download concurrently. \n",
    "- `search_dicts`: The search terms for creating the subset. All search terms from the web interface in all combinations are possible. One dictionary = one class.\n",
    "- `name`: Name of the subset to be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 'https://www.wga.hu/database/download/data_txt.zip'\n",
    "dir = 'wga'\n",
    "cc = 250\n",
    "search_dicts = [{'FORM': 'painting', 'TYPE': 'portrait'},\n",
    "                {'FORM': 'painting', 'TYPE': 'landscape'},\n",
    "                {'FORM': 'painting', 'TYPE': 'still-life'}]\n",
    "name = 'portrait-landscape-stilllife'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save remote image file to disk\n",
    "def save(url):\n",
    "    data = requests.get(url[0]).content\n",
    "    file = dir + '/' + url[1]\n",
    "    with open(file, 'wb') as f:\n",
    "        f.write(data)\n",
    "\n",
    "# Yield a list as chunks of size n\n",
    "def chunks(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "def show_image(img, fmt='jpeg'):\n",
    "    f = BytesIO()\n",
    "    PIL.Image.fromarray(img).save(f, fmt)\n",
    "    display(Image(data=f.getvalue()))\n",
    "    \n",
    "def equalize_classes(classes):\n",
    "    min_val = min([len(v) for v in classes.values()])\n",
    "    for k,v in classes.items():\n",
    "        classes[k] = classes[k][:min_val]    \n",
    "    \n",
    "def split_classes(subdir, classes, split_percent):\n",
    "    traindir = subdir + '/train'\n",
    "    if not os.path.exists(traindir): os.makedirs(traindir)\n",
    "    valdir = subdir + '/val'\n",
    "    if not os.path.exists(valdir): os.makedirs(valdir)\n",
    "    \n",
    "    for classname, classfiles in classes.items():\n",
    "        \n",
    "        classname = str(classname)\n",
    "        \n",
    "        if not os.path.exists(traindir + '/' + classname): os.makedirs(traindir + '/' + classname)\n",
    "        if not os.path.exists(valdir + '/' + classname): os.makedirs(valdir + '/' + classname)\n",
    "        \n",
    "        split = len(classfiles)-math.floor(len(classfiles)*split_percent)\n",
    "        trainfiles = classfiles[:split]\n",
    "        valfiles = classfiles[split:]\n",
    "        \n",
    "        for n, file in enumerate(trainfiles): copyfile(file, traindir + '/' + classname + '/%s.jpg' % n)\n",
    "        for n, file in enumerate(valfiles): copyfile(file, valdir + '/' + classname + '/%s.jpg' % n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the complete dataset\n",
    "\n",
    "This downloads the complete dataset concurrently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries to hold database information and image file locations.\n",
    "header_row = ['AUTHOR', 'BORN-DIED', 'TITLE', 'DATE', 'TECHNIQUE', 'LOCATION', 'URL', 'FORM', 'TYPE', 'SCHOOL', 'TIMEFRAME']\n",
    "header_dict = {v:k for k,v in enumerate(header_row)}\n",
    "header_dict_local = header_dict\n",
    "header_dict_local.update({'JPGURL': 11, 'FILE': 12})\n",
    "\n",
    "# Create directory to hold image files\n",
    "if not os.path.exists(dir): os.makedirs(dir)\n",
    "\n",
    "# Read remote zip file content into memory\n",
    "response = requests.get(source)\n",
    "zipfile = ZipFile(BytesIO(response.content))\n",
    "\n",
    "# There is only one file in the archive\n",
    "infile = zipfile.namelist()[0]\n",
    "\n",
    "# Encoding is ISO-8859, with some special characters replaced with '?' in the original file!\n",
    "iterator = [line.decode('ISO-8859-1') for line in zipfile.open(infile).readlines()]\n",
    "\n",
    "urls = []\n",
    "\n",
    "with open('catalog_local_utf8.csv', 'w', newline='') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=';', quotechar='\"')\n",
    "    reader = csv.reader(iterator, delimiter=';', quotechar='\"')\n",
    "    \n",
    "    for row in reader:\n",
    "\n",
    "        # Skip header\n",
    "        if row != header_row:\n",
    "                        \n",
    "            html_url = row[6]\n",
    "            jpg_url = html_url.replace('.html', '.jpg').replace('html', 'art') # Hacky regex\n",
    "            jpg_name = jpg_url.replace('https://www.wga.hu/art/', '').replace('/', '-')[2:] # Hacky regex\n",
    "            \n",
    "            row += [jpg_url, jpg_name]            \n",
    "            urls.append([jpg_url, jpg_name])\n",
    "            writer.writerow(row)\n",
    "\n",
    "done = 0\n",
    "total = math.ceil(len(urls)/cc)\n",
    "# Tqdm needs total provided for generators\n",
    "for chunk in tqdm_notebook(chunks(urls, cc), total=total):\n",
    "    jobs = [gevent.spawn(save, url) for url in chunk]\n",
    "    gevent.wait(jobs)\n",
    "    done += len(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create subset of dataset according to selected classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir = dir + '-' + name\n",
    "if not os.path.exists(subdir): os.makedirs(subdir)\n",
    "datadir = dir\n",
    "if not os.path.exists(datadir): os.makedirs(datadir)\n",
    "    \n",
    "classes = {} # Files for each class\n",
    "c = 0 # Class counter\n",
    "\n",
    "for search_dict in search_dicts:\n",
    "    \n",
    "    classes[c] = []\n",
    "    \n",
    "    with open('catalog_local_utf8.csv', 'r') as catalog:\n",
    "        reader = csv.reader(catalog, delimiter=';', quotechar='\"')\n",
    "        for row in reader:\n",
    "            matches = 0\n",
    "            for k,v in search_dict.items():\n",
    "                if row[header_dict_local[k]].lower() == v:\n",
    "                    matches += 1\n",
    "            if matches == len(search_dict):       \n",
    "                file = datadir + '/' + row[header_dict_local['FILE']]\n",
    "                classes[c] += [file]\n",
    "        \n",
    "        random.shuffle(classes[c])\n",
    "        c+=1\n",
    "        \n",
    "equalize_classes(classes)\n",
    "split_classes(subdir, classes, 0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
